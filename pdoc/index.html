<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>auditok API documentation</title>
    <meta name="description" content="`auditok` is a module that can be used as a generic tool for data
tokenization. Although its core mo..." />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">



    <li class="set"><h3><a href="#header-submodules">Sub-modules</a></h3>
      <ul>
        <li class="mono"><a href="core.m.html">auditok.core</a></li>
        <li class="mono"><a href="dataset.m.html">auditok.dataset</a></li>
        <li class="mono"><a href="io.m.html">auditok.io</a></li>
        <li class="mono"><a href="util.m.html">auditok.util</a></li>
      </ul>
    </li>
    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">auditok</span> module</h1>
  <p><code>auditok</code> is a module that can be used as a generic tool for data
tokenization. Although its core motivation is <strong>Acoustic Activity 
Detection</strong> (AAD) and extraction from audio streams (i.e. detect
where a noise/an acoustic activity occurs within an audio stream and
extract the corresponding portion of signal), it can easily be
adapted to other tasks.</p>
<p>Globally speaking, it can be used to extract, from a sequence of
observations, all sub-sequences that meet a certain number of
criteria in terms of:</p>
<ol>
<li>Minimum length of a <strong>valid</strong> token (i.e. sub-sequence)</li>
<li>Maximum length of a valid token</li>
<li>Maximum tolerated consecutive <strong>non-valid</strong> observations within
   a valid token</li>
</ol>
<p>Examples of a non-valid observation are: a non-numeric ascii symbol
if you are interested in sub-sequences of numeric symbols, or a silent
audio window (of 10, 20 or 100 milliseconds for instance) if what
interests you are audio regions made up of a sequence of ``noisy''
windows (whatever kind of noise: speech, baby cry, laughter, etc.).</p>
<p>The most important component of <code>auditok</code> is the <code>auditok.core.StreamTokenizer</code> class.
An instance of this class encapsulates a <code>DataValidator</code> and can be 
configured to detect the desired regions from a stream.
The <code>StreamTokenizer.tokenize</code> method accepts a <code>DataSource</code>
object that has a <code>read</code> method. Read data can be of any type accepted
by the <code>validator</code>.</p>
<p>As the main aim of this module is <strong>Audio Activity Detection</strong>,
it provides the <code>auditok.util.ADSFactory</code> factory class that makes
it very easy to create an <code>AudioDataSource</code> (a class that implements <code>DataSource</code>)
 object, be that from:</p>
<ul>
<li>A file on the disk</li>
<li>A buffer of data</li>
<li>The built-in microphone (requires PyAudio)</li>
</ul>
<p>The <code>AudioDataSource</code> class inherits from <code>DataSource</code> and supplies
a higher abstraction level than <code>AudioSource</code> thanks to a bunch of
handy features:</p>
<ul>
<li>Define a fixed-length of block_size (i.e. analysis window)</li>
<li>Allow overlap between two consecutive analysis windows (hop_size &lt; block_size).
   This can be very important if your validator use the <strong>spectral</strong> 
   information of audio data instead of raw audio samples.</li>
<li>Limit the amount (i.e. duration) of read data (very useful when reading
   data from the microphone)</li>
<li>Record and rewind data (also useful if you read data from the microphone
   and you want to process it many times offline and/or save it)  </li>
</ul>
<p>Last but not least, the current version has only one audio window validator based on
signal energy.</p>
<h2>Requirements:</h2>
<p><code>auditok</code> requires <a href="http://people.csail.mit.edu/hubert/pyaudio/">Pyaudio</a> for audio acquisition and playback.</p>
<h2>Illustrative examples with strings</h2>
<p>Let us look at some examples using the <code>auditok.util.StringDataSource</code> class
created for test and illustration purposes. Imagine that each character of 
<code>auditok.util.StringDataSource</code> data represent an audio slice of 100 ms for
example. In the following examples we will use upper case letters to represent
noisy audio slices (i.e. analysis windows or frames) and lower case letter for
silent frames.</p>
<h2>Extract sub-sequences of consecutive upper case letters</h2>
<p>We want to extract sub-sequences of characters that have:</p>
<ul>
<li>A minimu length of 1 (<code>min_length</code> = 1)</li>
<li>A maximum length of 9999 (<code>max_length</code> = 9999)</li>
<li>Zero consecutive lower case characters within them (<code>max_continuous_silence</code> = 0)</li>
</ul>
<p>We also create the <code>UpperCaseChecker</code> whose <code>read</code> method returns <code>True</code> if the 
checked character is in upper case and <code>False</code> otherwise. </p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">StringDataSource</span><span class="p">,</span> <span class="n">DataValidator</span>

<span class="k">class</span> <span class="nc">UpperCaseChecker</span><span class="p">(</span><span class="n">DataValidator</span><span class="p">):</span>
   <span class="k">def</span> <span class="nf">is_valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">frame</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>

<span class="n">dsource</span> <span class="o">=</span> <span class="n">StringDataSource</span><span class="p">(</span><span class="s">&quot;aaaABCDEFbbGHIJKccc&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="o">=</span><span class="n">UpperCaseChecker</span><span class="p">(),</span> 
             <span class="n">min_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">dsource</span><span class="p">)</span>
</pre></div>


<p>The output is a list of two tuples, each contains the extracted sub-sequence and its
start and end position in the original sequence respectively:</p>
<div class="codehilite"><pre><span class="p">[([</span><span class="s">&#39;A&#39;</span><span class="p">,</span> <span class="s">&#39;B&#39;</span><span class="p">,</span> <span class="s">&#39;C&#39;</span><span class="p">,</span> <span class="s">&#39;D&#39;</span><span class="p">,</span> <span class="s">&#39;E&#39;</span><span class="p">,</span> <span class="s">&#39;F&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">([</span><span class="s">&#39;G&#39;</span><span class="p">,</span> <span class="s">&#39;H&#39;</span><span class="p">,</span> <span class="s">&#39;I&#39;</span><span class="p">,</span> <span class="s">&#39;J&#39;</span><span class="p">,</span> <span class="s">&#39;K&#39;</span><span class="p">],</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">15</span><span class="p">)]</span>
</pre></div>


<h2>Tolerate up to 2 non-valid (lower case) letters within an extracted sequence</h2>
<p>To do so, we set <code>max_continuous_silence</code>=2:</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">StringDataSource</span><span class="p">,</span> <span class="n">DataValidator</span>

<span class="k">class</span> <span class="nc">UpperCaseChecker</span><span class="p">(</span><span class="n">DataValidator</span><span class="p">):</span>
   <span class="k">def</span> <span class="nf">is_valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">frame</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>

<span class="n">dsource</span> <span class="o">=</span> <span class="n">StringDataSource</span><span class="p">(</span><span class="s">&quot;aaaABCDbbEFcGHIdddJKee&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="o">=</span><span class="n">UpperCaseChecker</span><span class="p">(),</span> 
             <span class="n">min_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">dsource</span><span class="p">)</span>
</pre></div>


<p>output:</p>
<div class="codehilite"><pre><span class="p">[([</span><span class="s">&#39;A&#39;</span><span class="p">,</span> <span class="s">&#39;B&#39;</span><span class="p">,</span> <span class="s">&#39;C&#39;</span><span class="p">,</span> <span class="s">&#39;D&#39;</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="s">&#39;E&#39;</span><span class="p">,</span> <span class="s">&#39;F&#39;</span><span class="p">,</span> <span class="s">&#39;c&#39;</span><span class="p">,</span> <span class="s">&#39;G&#39;</span><span class="p">,</span> <span class="s">&#39;H&#39;</span><span class="p">,</span> <span class="s">&#39;I&#39;</span><span class="p">,</span> <span class="s">&#39;d&#39;</span><span class="p">,</span> <span class="s">&#39;d&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">16</span><span class="p">),</span> <span class="p">([</span><span class="s">&#39;J&#39;</span><span class="p">,</span> <span class="s">&#39;K&#39;</span><span class="p">,</span> <span class="s">&#39;e&#39;</span><span class="p">,</span> <span class="s">&#39;e&#39;</span><span class="p">],</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">21</span><span class="p">)]</span>
</pre></div>


<p>Notice the tailing lower case letters "dd" and "ee" at the end of the two
tokens. The default behavior of <code>StreamTokenizer</code> is to keep the <em>tailing
silence</em> if it does'nt exceed <code>max_continuous_silence</code>. This can be changed
using the <code>DROP_TAILING_SILENCE</code> mode (see next example).</p>
<h2>Remove tailing silence</h2>
<p>Tailing silence can be useful for many sound recognition applications, including
speech recognition. Moreover, from the human auditory system point of view, tailing
low energy signal helps removing abrupt signal cuts.</p>
<p>If you want to remove it anyway, you can do it by setting <code>mode</code> to <code>StreamTokenizer.DROP_TAILING_SILENCE</code>:</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">StringDataSource</span><span class="p">,</span> <span class="n">DataValidator</span>

<span class="k">class</span> <span class="nc">UpperCaseChecker</span><span class="p">(</span><span class="n">DataValidator</span><span class="p">):</span>
   <span class="k">def</span> <span class="nf">is_valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">frame</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>

<span class="n">dsource</span> <span class="o">=</span> <span class="n">StringDataSource</span><span class="p">(</span><span class="s">&quot;aaaABCDbbEFcGHIdddJKee&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="o">=</span><span class="n">UpperCaseChecker</span><span class="p">(),</span> 
             <span class="n">min_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">9999</span><span class="p">,</span> <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
             <span class="n">mode</span><span class="o">=</span><span class="n">StreamTokenizer</span><span class="o">.</span><span class="n">DROP_TAILING_SILENCE</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">dsource</span><span class="p">)</span>
</pre></div>


<p>output:</p>
<div class="codehilite"><pre><span class="p">[([</span><span class="s">&#39;A&#39;</span><span class="p">,</span> <span class="s">&#39;B&#39;</span><span class="p">,</span> <span class="s">&#39;C&#39;</span><span class="p">,</span> <span class="s">&#39;D&#39;</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="s">&#39;b&#39;</span><span class="p">,</span> <span class="s">&#39;E&#39;</span><span class="p">,</span> <span class="s">&#39;F&#39;</span><span class="p">,</span> <span class="s">&#39;c&#39;</span><span class="p">,</span> <span class="s">&#39;G&#39;</span><span class="p">,</span> <span class="s">&#39;H&#39;</span><span class="p">,</span> <span class="s">&#39;I&#39;</span><span class="p">],</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="p">([</span><span class="s">&#39;J&#39;</span><span class="p">,</span> <span class="s">&#39;K&#39;</span><span class="p">],</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">19</span><span class="p">)]</span>
</pre></div>


<h2>Limit the length of detected tokens</h2>
<p>Imagine that you just want to detect and recognize a small part of a long
acoustic event (e.g. engine noise, water flow, etc.) and avoid that that 
event hogs the tokenizer and prevent it from feeding the event to the next
processing step (i.e. a sound recognizer). You can do this by:</p>
<ul>
<li>limiting the length of a detected token.</li>
</ul>
<p>and</p>
<ul>
<li>using a callback function as an argument to <code>StreamTokenizer.tokenize</code> 
   so that the tokenizer delivers a token as soon as it is detected.</li>
</ul>
<p>The following code limits the length of a token to 5:</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">StringDataSource</span><span class="p">,</span> <span class="n">DataValidator</span>

<span class="k">class</span> <span class="nc">UpperCaseChecker</span><span class="p">(</span><span class="n">DataValidator</span><span class="p">):</span>
   <span class="k">def</span> <span class="nf">is_valid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">frame</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span>

<span class="n">dsource</span> <span class="o">=</span> <span class="n">StringDataSource</span><span class="p">(</span><span class="s">&quot;aaaABCDEFGHIJKbbb&quot;</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="o">=</span><span class="n">UpperCaseChecker</span><span class="p">(),</span>
             <span class="n">min_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">print_token</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;token = &#39;{0}&#39;, starts at {1}, ends at {2}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">dsource</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">print_token</span><span class="p">)</span>
</pre></div>


<p>output:</p>
<div class="codehilite"><pre>&quot;token = &#39;ABCDE&#39;, starts at 3, ends at 7&quot;
&quot;token = &#39;FGHIJ&#39;, starts at 8, ends at 12&quot;
&quot;token = &#39;K&#39;, starts at 13, ends at 13&quot;
</pre></div>


<h2>Using real audio data</h2>
<p>In this section we will use <code>ADSFactory</code>, <code>AudioEnergyValidator</code> and <code>StreamTokenizer</code>
for an AAD demonstration using audio data. Before we get any, further it is worth
explaining a certain number of points.</p>
<p><code>ADSFactory.ads</code> method is called to create an <code>AudioDataSource</code> object that can be
passed to  <code>StreamTokenizer.tokenize</code>. <code>ADSFactory.ads</code> accepts a number of keyword
arguments, of which none is mandatory. The returned <code>AudioDataSource</code> object can 
however greatly differ depending on the passed arguments. Further details can be found
in the respective method documentation. Note however the following two calls that will
create an <code>AudioDataSource</code> that read data from an audio file and from the built-in
microphone respectively.</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">ADSFactory</span>

<span class="c"># Get an AudioDataSource from a file</span>
<span class="n">file_ads</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">filename</span> <span class="o">=</span> <span class="s">&quot;path/to/file/&quot;</span><span class="p">)</span>

<span class="c"># Get an AudioDataSource from the built-in microphone</span>
<span class="c"># The returned object has the default values for sampling</span>
<span class="c"># rate, sample width an number of channels. see method&#39;s</span>
<span class="c"># documentation for customized values </span>
<span class="n">mic_ads</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">()</span>
</pre></div>


<p>For <code>StreamTkenizer</code>, parameters <code>min_length</code>, <code>max_length</code> and <code>max_continuous_silence</code>
are expressed in term of number of frames. If you want a <code>max_length</code> of <em>2 seconds</em> for
your detected sound events and your <em>analysis window</em> is <em>10 ms</em> long, you have to specify
a <code>max_length</code> of 200 (<code>int(2. / (10. / 1000)) == 200</code>). For a <code>max_continuous_silence</code> of <em>300 ms</em>
for instance, the value to pass to StreamTokenizer is 30 (<code>int(0.3 / (10. / 1000)) == 30</code>).</p>
<p>Where do you get the size of the <strong>analysis window</strong> from?</p>
<p>Well this is a parameter you pass to <code>ADSFactory.ads</code>. By default <code>ADSFactory.ads</code> uses
an analysis window of 10 ms. the number of samples that 10 ms of signal contain will
vary depending on the sampling rate of your audio source (file, microphone, etc.).
For a sampling rate of 16KHz (16000 samples per second), we have 160 samples for 10 ms.
Therefore you can use block sizes of 160, 320, 1600 for analysis windows of 10, 20 and 100 
ms respectively.</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">ADSFactory</span>

<span class="n">file_ads</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">filename</span> <span class="o">=</span> <span class="s">&quot;path/to/file/&quot;</span><span class="p">,</span> <span class="n">block_size</span> <span class="o">=</span> <span class="mi">160</span><span class="p">)</span>

<span class="n">file_ads</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">filename</span> <span class="o">=</span> <span class="s">&quot;path/to/file/&quot;</span><span class="p">,</span> <span class="n">block_size</span> <span class="o">=</span> <span class="mi">320</span><span class="p">)</span>

<span class="c"># If no sampling rate is specified, ADSFactory use 16KHz as the default</span>
<span class="c"># rate for the microphone. If you want to use a window of 100 ms, use </span>
<span class="c"># a block size of 1600 </span>
<span class="n">mic_ads</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">1600</span><span class="p">)</span>
</pre></div>


<p>So if your not sure what you analysis windows in seconds is, use the following:</p>
<div class="codehilite"><pre><span class="n">my_ads</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="n">analysis_win_seconds</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">my_ads</span><span class="o">.</span><span class="n">get_block_size</span><span class="p">())</span> <span class="o">/</span> <span class="n">my_ads</span><span class="o">.</span><span class="n">get_sampling_rate</span><span class="p">()</span>
<span class="n">analysis_window_ms</span> <span class="o">=</span> <span class="n">analysis_win_seconds</span> <span class="o">*</span> <span class="mi">1000</span>

<span class="c"># For a `max_continuous_silence` of 300 ms use:</span>
<span class="n">max_continuous_silence</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">300.</span> <span class="o">/</span> <span class="n">analysis_window_ms</span><span class="p">)</span>

<span class="c"># Which is the same as</span>
<span class="n">max_continuous_silence</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">/</span> <span class="p">(</span><span class="n">analysis_window_ms</span> <span class="o">/</span> <span class="mi">1000</span><span class="p">))</span>
</pre></div>


<h2>Examples</h2>
<h2>Extract isolated phrases from an utterance</h2>
<p>We will build an <code>AudioDataSource</code> using a wave file from  the database.
The file contains of isolated pronunciation of digits from 1 to 1
in Arabic as well as breath-in/out between 2 and 3. The code will play the
 original file then the detected sounds separately. Note that we use an 
<code>energy_threshold</code> of 65, this parameter should be carefully chosen. It depends
on microphone quality, background noise and the amplitude of events you want to 
detect.</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">ADSFactory</span><span class="p">,</span> <span class="n">AudioEnergyValidator</span><span class="p">,</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">player_for</span><span class="p">,</span> <span class="n">dataset</span>

<span class="c"># We set the `record` argument to True so that we can rewind the source</span>
<span class="n">asource</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">one_to_six_arabic_16000_mono_bc_noise</span><span class="p">,</span> <span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">validator</span> <span class="o">=</span> <span class="n">AudioEnergyValidator</span><span class="p">(</span><span class="n">sample_width</span><span class="o">=</span><span class="n">asource</span><span class="o">.</span><span class="n">get_sample_width</span><span class="p">(),</span> <span class="n">energy_threshold</span><span class="o">=</span><span class="mi">65</span><span class="p">)</span>

<span class="c"># Defalut analysis window is 10 ms (float(asource.get_block_size()) / asource.get_sampling_rate())</span>
<span class="c"># min_length=20 : minimum length of a valid audio activity is 20 * 10 == 200 ms</span>
<span class="c"># max_length=4000 :  maximum length of a valid audio activity is 400 * 10 == 4000 ms == 4 seconds</span>
<span class="c"># max_continuous_silence=30 : maximum length of a tolerated  silence within a valid audio activity is 30 * 30 == 300 ms </span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="o">=</span><span class="n">validator</span><span class="p">,</span> <span class="n">min_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">asource</span><span class="o">.</span><span class="n">open</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">asource</span><span class="p">)</span>

<span class="c"># Play detected regions back</span>

<span class="n">player</span> <span class="o">=</span> <span class="n">player_for</span><span class="p">(</span><span class="n">asource</span><span class="p">)</span>

<span class="c"># Rewind and read the whole signal</span>
<span class="n">asource</span><span class="o">.</span><span class="n">rewind</span><span class="p">()</span>
<span class="n">original_signal</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
   <span class="n">w</span> <span class="o">=</span> <span class="n">asource</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
   <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">break</span>
   <span class="n">original_signal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="n">original_signal</span> <span class="o">=</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">original_signal</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;Playing the original file...&quot;</span><span class="p">)</span>
<span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">original_signal</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;playing detected regions...&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">&quot;Token starts at {0} and ends at {1}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">data</span> <span class="o">=</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">8</span>
</pre></div>


<p>The tokenizer extracts 8 audio regions from the signal, including all isolated digits
(from 1 to 6) as well as the 2-phase respiration of the subject. You might have noticed
that, in the original file, the last three digit are closer to each other than the 
previous ones. If you wan them to be extracted as one single phrase, you can do so
by tolerating a larger continuous silence within a detection:</p>
<div class="codehilite"><pre><span class="n">tokenizer</span><span class="o">.</span><span class="n">max_continuous_silence</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">asource</span><span class="o">.</span><span class="n">rewind</span><span class="p">()</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">asource</span><span class="p">)</span>

<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
   <span class="k">print</span><span class="p">(</span><span class="s">&quot;Token starts at {0} and ends at {1}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">t</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
   <span class="n">data</span> <span class="o">=</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
   <span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span>
</pre></div>


<h2>Trim leading and tailing silence</h2>
<p>The  tokenizer in the following example is set up to remove the silence
that precedes the first acoustic activity or follows the last activity 
in a record. It preserves whatever it founds between the two activities.
In other words, it removes the leading and tailing silence.</p>
<p>Sampling rate is 44100 sample per second, we'll use an analysis window of 100 ms
(i.e. bloc_ksize == 4410)</p>
<p>Energy threshold is 50.</p>
<p>The tokenizer will start accumulating windows up from the moment it encounters
the first analysis window of an energy &gt;= 50. ALL the following windows will be 
kept regardless of their energy. At the end of the analysis, it will drop tailing
 windows with an energy below 50.</p>
<p>This is an interesting example because the audio file we're analyzing contains a very
brief noise that occurs within the leading silence. We certainly do want our tokenizer 
to stop at this point and considers whatever it comes after as a useful signal.
To force the tokenizer to ignore that brief event we use two other parameters <code>init_min</code>
ans <code>init_max_silence</code>. By <code>init_min</code>=3 and <code>init_max_silence</code>=1 we tell the tokenizer
that a valid event must start with at least 3 noisy windows, between which there
is at most 1 silent window.</p>
<p>Still with this configuration we can get the tokenizer detect that noise as a valid event
(if it actually contains 3 consecutive noisy frames). To circummvent this we use an enough
large analysis window (here of 100 ms) to ensure that the brief noise be surrounded by a much
longer silence and hence the energy of the overall analysis window will be below 50.</p>
<p>When using a shorter analysis window (of 10ms for instance, block_size == 441), the brief
noise contributes more to energy calculation which yields an energy of over 50 for the window.
Again we can deal with this situation by using a higher energy threshold (55 for example)</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">ADSFactory</span><span class="p">,</span> <span class="n">AudioEnergyValidator</span><span class="p">,</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">player_for</span><span class="p">,</span> <span class="n">dataset</span>

<span class="c"># record = True so that we&#39;ll be able to rewind the source.</span>
<span class="n">asource</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">filename</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">was_der_mensch_saet_mono_44100_lead_tail_silence</span><span class="p">,</span>
         <span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">4410</span><span class="p">)</span>
<span class="n">asource</span><span class="o">.</span><span class="n">open</span><span class="p">()</span>

<span class="n">original_signal</span> <span class="o">=</span> <span class="p">[]</span>
<span class="c"># Read the whole signal</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
   <span class="n">w</span> <span class="o">=</span> <span class="n">asource</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
   <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="k">break</span>
   <span class="n">original_signal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="n">original_signal</span> <span class="o">=</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">original_signal</span><span class="p">)</span>

<span class="c"># rewind source</span>
<span class="n">asource</span><span class="o">.</span><span class="n">rewind</span><span class="p">()</span>

<span class="c"># Create a validator with an energy threshold of 50</span>
<span class="n">validator</span> <span class="o">=</span> <span class="n">AudioEnergyValidator</span><span class="p">(</span><span class="n">sample_width</span><span class="o">=</span><span class="n">asource</span><span class="o">.</span><span class="n">get_sample_width</span><span class="p">(),</span> <span class="n">energy_threshold</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>

<span class="c"># Create a tokenizer with an unlimited token length and continuous silence within a token</span>
<span class="c"># Note the DROP_TAILING_SILENCE mode that will ensure removing tailing silence</span>
<span class="n">trimmer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="p">,</span> <span class="n">min_length</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">99999999</span><span class="p">,</span> <span class="n">init_min</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">init_max_silence</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                         <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">9999999</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="n">StreamTokenizer</span><span class="o">.</span><span class="n">DROP_TAILING_SILENCE</span><span class="p">)</span>


<span class="n">tokens</span> <span class="o">=</span> <span class="n">trimmer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">asource</span><span class="p">)</span>

<span class="c"># Make sure we only have one token</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="s">&quot;Should have detected one single token&quot;</span>

<span class="n">trimmed_signal</span> <span class="o">=</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

<span class="n">player</span> <span class="o">=</span> <span class="n">player_for</span><span class="p">(</span><span class="n">asource</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">&quot;Playing original signal (with leading and tailing silence)...&quot;</span><span class="p">)</span>
<span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">original_signal</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">&quot;Playing trimmed signal...&quot;</span><span class="p">)</span>
<span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">trimmed_signal</span><span class="p">)</span>
</pre></div>


<h2>Online audio signal processing</h2>
<p>In the next example, audio data is directely acquired from the built-in microphone.
The <code>tokenize</code> method is passed a callback function so that audio activities
are delivered as soon as they are detected. Each detected activity is played
back using the build-in audio output device.</p>
<p>As mentionned before , Signal energy is strongly related to many factors such
microphone sensitivity, background noise (including noise inherent to the hardware), 
distance and your operating system sound settings. Try a lower <code>energy_threshold</code>
if your noise does not seem to be detected and a higher threshold if you notice
an over detection (echo method prints a detection where you have made no noise).</p>
<div class="codehilite"><pre><span class="kn">from</span> <span class="nn">auditok</span> <span class="kn">import</span> <span class="n">ADSFactory</span><span class="p">,</span> <span class="n">AudioEnergyValidator</span><span class="p">,</span> <span class="n">StreamTokenizer</span><span class="p">,</span> <span class="n">player_for</span>

<span class="c"># record = True so that we&#39;ll be able to rewind the source.</span>
<span class="c"># max_time = 10: read 10 seconds from the microphone</span>
<span class="n">asource</span> <span class="o">=</span> <span class="n">ADSFactory</span><span class="o">.</span><span class="n">ads</span><span class="p">(</span><span class="n">record</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">max_time</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">validator</span> <span class="o">=</span> <span class="n">AudioEnergyValidator</span><span class="p">(</span><span class="n">sample_width</span><span class="o">=</span><span class="n">asource</span><span class="o">.</span><span class="n">get_sample_width</span><span class="p">(),</span> <span class="n">energy_threshold</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">StreamTokenizer</span><span class="p">(</span><span class="n">validator</span><span class="o">=</span><span class="n">validator</span><span class="p">,</span> <span class="n">min_length</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">max_continuous_silence</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>

<span class="n">player</span> <span class="o">=</span> <span class="n">player_for</span><span class="p">(</span><span class="n">asource</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">echo</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">):</span>
   <span class="k">print</span><span class="p">(</span><span class="s">&quot;Acoustic activity at: {0}--{1}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">end</span><span class="p">))</span>
   <span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data</span><span class="p">))</span>

<span class="n">asource</span><span class="o">.</span><span class="n">open</span><span class="p">()</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">asource</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">echo</span><span class="p">)</span>
</pre></div>


<p>If you want to re-run the tokenizer after changing of one or many parameters, use the following code:</p>
<div class="codehilite"><pre><span class="n">asource</span><span class="o">.</span><span class="n">rewind</span><span class="p">()</span>
<span class="c"># change energy threshold for example</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">validator</span><span class="o">.</span><span class="n">set_energy_threshold</span><span class="p">(</span><span class="mi">55</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">asource</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">echo</span><span class="p">)</span>
</pre></div>


<p>In case you want to play the whole recorded signal back use:</p>
<div class="codehilite"><pre><span class="n">player</span><span class="o">.</span><span class="n">play</span><span class="p">(</span><span class="n">asource</span><span class="o">.</span><span class="n">get_audio_source</span><span class="p">()</span><span class="o">.</span><span class="n">get_data_buffer</span><span class="p">())</span>
</pre></div>


<h2>Contributing</h2>
<p><code>auditok</code> is on <a href="https://github.com/amsehili">GitHub</a>. You're welcome to fork
it and contribute.</p>
<p>@author: Amine SEHILI <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a>
September, 2015</p>
<h2>License</h2>
<p>This package is published under GNU GPL Version 3.</p>
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-auditok', this);">Show source &equiv;</a></p>
  <div id="source-auditok" class="source">
    <div class="codehilite"><pre><span class="sd">&quot;&quot;&quot;</span>

<span class="sd">`auditok` is a module that can be used as a generic tool for data</span>
<span class="sd">tokenization. Although its core motivation is **Acoustic Activity </span>
<span class="sd">Detection** (AAD) and extraction from audio streams (i.e. detect</span>
<span class="sd">where a noise/an acoustic activity occurs within an audio stream and</span>
<span class="sd">extract the corresponding portion of signal), it can easily be</span>
<span class="sd">adapted to other tasks.</span>

<span class="sd">Globally speaking, it can be used to extract, from a sequence of</span>
<span class="sd">observations, all sub-sequences that meet a certain number of</span>
<span class="sd">criteria in terms of:</span>

<span class="sd">1. Minimum length of a **valid** token (i.e. sub-sequence)</span>
<span class="sd">2. Maximum length of a valid token</span>
<span class="sd">3. Maximum tolerated consecutive **non-valid** observations within</span>
<span class="sd">   a valid token</span>

<span class="sd">Examples of a non-valid observation are: a non-numeric ascii symbol</span>
<span class="sd">if you are interested in sub-sequences of numeric symbols, or a silent</span>
<span class="sd">audio window (of 10, 20 or 100 milliseconds for instance) if what</span>
<span class="sd">interests you are audio regions made up of a sequence of ``noisy&#39;&#39;</span>
<span class="sd">windows (whatever kind of noise: speech, baby cry, laughter, etc.).</span>

<span class="sd">The most important component of `auditok` is the `auditok.core.StreamTokenizer` class.</span>
<span class="sd">An instance of this class encapsulates a `DataValidator` and can be </span>
<span class="sd">configured to detect the desired regions from a stream.</span>
<span class="sd">The `StreamTokenizer.tokenize` method accepts a `DataSource`</span>
<span class="sd">object that has a `read` method. Read data can be of any type accepted</span>
<span class="sd">by the `validator`.</span>


<span class="sd">As the main aim of this module is **Audio Activity Detection**,</span>
<span class="sd">it provides the `auditok.util.ADSFactory` factory class that makes</span>
<span class="sd">it very easy to create an `AudioDataSource` (a class that implements `DataSource`)</span>
<span class="sd"> object, be that from:</span>

<span class="sd"> - A file on the disk</span>
<span class="sd"> - A buffer of data</span>
<span class="sd"> - The built-in microphone (requires PyAudio)</span>
<span class="sd"> </span>

<span class="sd">The `AudioDataSource` class inherits from `DataSource` and supplies</span>
<span class="sd">a higher abstraction level than `AudioSource` thanks to a bunch of</span>
<span class="sd">handy features:</span>

<span class="sd"> - Define a fixed-length of block_size (i.e. analysis window)</span>
<span class="sd"> - Allow overlap between two consecutive analysis windows (hop_size &lt; block_size).</span>
<span class="sd">   This can be very important if your validator use the **spectral** </span>
<span class="sd">   information of audio data instead of raw audio samples.</span>
<span class="sd"> - Limit the amount (i.e. duration) of read data (very useful when reading</span>
<span class="sd">   data from the microphone)</span>
<span class="sd"> - Record and rewind data (also useful if you read data from the microphone</span>
<span class="sd">   and you want to process it many times offline and/or save it)  </span>


<span class="sd">Last but not least, the current version has only one audio window validator based on</span>
<span class="sd">signal energy.</span>

<span class="sd">Requirements:</span>
<span class="sd">------------</span>
<span class="sd">`auditok` requires [Pyaudio](http://people.csail.mit.edu/hubert/pyaudio/) for audio acquisition and playback.</span>



<span class="sd">Illustrative examples with strings</span>
<span class="sd">----------------------------------</span>
<span class="sd">Let us look at some examples using the `auditok.util.StringDataSource` class</span>
<span class="sd">created for test and illustration purposes. Imagine that each character of </span>
<span class="sd">`auditok.util.StringDataSource` data represent an audio slice of 100 ms for</span>
<span class="sd">example. In the following examples we will use upper case letters to represent</span>
<span class="sd">noisy audio slices (i.e. analysis windows or frames) and lower case letter for</span>
<span class="sd">silent frames.</span>

<span class="sd">## Extract sub-sequences of consecutive upper case letters</span>
<span class="sd">We want to extract sub-sequences of characters that have:</span>
<span class="sd">    </span>
<span class="sd">  - A minimu length of 1 (`min_length` = 1)</span>
<span class="sd">  - A maximum length of 9999 (`max_length` = 9999)</span>
<span class="sd">  - Zero consecutive lower case characters within them (`max_continuous_silence` = 0)</span>

<span class="sd">We also create the `UpperCaseChecker` whose `read` method returns `True` if the </span>
<span class="sd">checked character is in upper case and `False` otherwise. </span>
<span class="sd"> </span>
<span class="sd">    #!python</span>
<span class="sd">    from auditok import StreamTokenizer, StringDataSource, DataValidator</span>
<span class="sd">    </span>
<span class="sd">    class UpperCaseChecker(DataValidator):</span>
<span class="sd">       def is_valid(self, frame):</span>
<span class="sd">          return frame.isupper()</span>
<span class="sd">    </span>
<span class="sd">    dsource = StringDataSource(&quot;aaaABCDEFbbGHIJKccc&quot;)</span>
<span class="sd">    tokenizer = StreamTokenizer(validator=UpperCaseChecker(), </span>
<span class="sd">                 min_length=1, max_length=9999, max_continuous_silence=0)</span>
<span class="sd">                 </span>
<span class="sd">    tokenizer.tokenize(dsource)</span>

<span class="sd">The output is a list of two tuples, each contains the extracted sub-sequence and its</span>
<span class="sd">start and end position in the original sequence respectively:</span>

<span class="sd">    #!python</span>
<span class="sd">    [([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39;, &#39;F&#39;], 3, 8), ([&#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;J&#39;, &#39;K&#39;], 11, 15)]</span>
<span class="sd">    </span>
<span class="sd">## Tolerate up to 2 non-valid (lower case) letters within an extracted sequence</span>

<span class="sd">To do so, we set `max_continuous_silence`=2:</span>

<span class="sd">    #!python</span>
<span class="sd">    from auditok import StreamTokenizer, StringDataSource, DataValidator</span>
<span class="sd">    </span>
<span class="sd">    class UpperCaseChecker(DataValidator):</span>
<span class="sd">       def is_valid(self, frame):</span>
<span class="sd">          return frame.isupper()</span>
<span class="sd">    </span>
<span class="sd">    dsource = StringDataSource(&quot;aaaABCDbbEFcGHIdddJKee&quot;)</span>
<span class="sd">    tokenizer = StreamTokenizer(validator=UpperCaseChecker(), </span>
<span class="sd">                 min_length=1, max_length=9999, max_continuous_silence=2)</span>
<span class="sd">                 </span>
<span class="sd">    tokenizer.tokenize(dsource)</span>

<span class="sd">output:</span>

<span class="sd">    #!python</span>
<span class="sd">    [([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;b&#39;, &#39;b&#39;, &#39;E&#39;, &#39;F&#39;, &#39;c&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;, &#39;d&#39;, &#39;d&#39;], 3, 16), ([&#39;J&#39;, &#39;K&#39;, &#39;e&#39;, &#39;e&#39;], 18, 21)]</span>
<span class="sd">    </span>
<span class="sd">Notice the tailing lower case letters &quot;dd&quot; and &quot;ee&quot; at the end of the two</span>
<span class="sd">tokens. The default behavior of `StreamTokenizer` is to keep the *tailing</span>
<span class="sd">silence* if it does&#39;nt exceed `max_continuous_silence`. This can be changed</span>
<span class="sd">using the `DROP_TAILING_SILENCE` mode (see next example).</span>

<span class="sd">## Remove tailing silence</span>

<span class="sd">Tailing silence can be useful for many sound recognition applications, including</span>
<span class="sd">speech recognition. Moreover, from the human auditory system point of view, tailing</span>
<span class="sd">low energy signal helps removing abrupt signal cuts.</span>

<span class="sd">If you want to remove it anyway, you can do it by setting `mode` to `StreamTokenizer.DROP_TAILING_SILENCE`:</span>


<span class="sd">    #!python</span>
<span class="sd">    from auditok import StreamTokenizer, StringDataSource, DataValidator</span>
<span class="sd">    </span>
<span class="sd">    class UpperCaseChecker(DataValidator):</span>
<span class="sd">       def is_valid(self, frame):</span>
<span class="sd">          return frame.isupper()</span>
<span class="sd">    </span>
<span class="sd">    dsource = StringDataSource(&quot;aaaABCDbbEFcGHIdddJKee&quot;)</span>
<span class="sd">    tokenizer = StreamTokenizer(validator=UpperCaseChecker(), </span>
<span class="sd">                 min_length=1, max_length=9999, max_continuous_silence=2,</span>
<span class="sd">                 mode=StreamTokenizer.DROP_TAILING_SILENCE)</span>
<span class="sd">                 </span>
<span class="sd">    tokenizer.tokenize(dsource)</span>

<span class="sd">output:</span>

<span class="sd">    #!python</span>
<span class="sd">    [([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;b&#39;, &#39;b&#39;, &#39;E&#39;, &#39;F&#39;, &#39;c&#39;, &#39;G&#39;, &#39;H&#39;, &#39;I&#39;], 3, 14), ([&#39;J&#39;, &#39;K&#39;], 18, 19)]</span>


<span class="sd">## Limit the length of detected tokens</span>

<span class="sd">Imagine that you just want to detect and recognize a small part of a long</span>
<span class="sd">acoustic event (e.g. engine noise, water flow, etc.) and avoid that that </span>
<span class="sd">event hogs the tokenizer and prevent it from feeding the event to the next</span>
<span class="sd">processing step (i.e. a sound recognizer). You can do this by:</span>

<span class="sd"> - limiting the length of a detected token.</span>
<span class="sd"> </span>
<span class="sd"> and</span>
<span class="sd"> </span>
<span class="sd"> - using a callback function as an argument to `StreamTokenizer.tokenize` </span>
<span class="sd">   so that the tokenizer delivers a token as soon as it is detected.</span>

<span class="sd">The following code limits the length of a token to 5:</span>

<span class="sd">    #!python</span>
<span class="sd">    from auditok import StreamTokenizer, StringDataSource, DataValidator</span>
<span class="sd">    </span>
<span class="sd">    class UpperCaseChecker(DataValidator):</span>
<span class="sd">       def is_valid(self, frame):</span>
<span class="sd">          return frame.isupper()</span>
<span class="sd">    </span>
<span class="sd">    dsource = StringDataSource(&quot;aaaABCDEFGHIJKbbb&quot;)</span>
<span class="sd">    tokenizer = StreamTokenizer(validator=UpperCaseChecker(),</span>
<span class="sd">                 min_length=1, max_length=5, max_continuous_silence=0)</span>
<span class="sd">                 </span>
<span class="sd">    def print_token(data, start, end):</span>
<span class="sd">        print(&quot;token = &#39;{0}&#39;, starts at {1}, ends at {2}&quot;.format(&#39;&#39;.join(data), start, end))</span>
<span class="sd">                 </span>
<span class="sd">    tokenizer.tokenize(dsource, callback=print_token)</span>
<span class="sd">    </span>

<span class="sd">output:</span>

<span class="sd">    &quot;token = &#39;ABCDE&#39;, starts at 3, ends at 7&quot;</span>
<span class="sd">    &quot;token = &#39;FGHIJ&#39;, starts at 8, ends at 12&quot;</span>
<span class="sd">    &quot;token = &#39;K&#39;, starts at 13, ends at 13&quot;</span>


<span class="sd">Using real audio data</span>
<span class="sd">-------------------------------</span>
<span class="sd">In this section we will use `ADSFactory`, `AudioEnergyValidator` and `StreamTokenizer`</span>
<span class="sd">for an AAD demonstration using audio data. Before we get any, further it is worth</span>
<span class="sd">explaining a certain number of points.</span>

<span class="sd">`ADSFactory.ads` method is called to create an `AudioDataSource` object that can be</span>
<span class="sd">passed to  `StreamTokenizer.tokenize`. `ADSFactory.ads` accepts a number of keyword</span>
<span class="sd">arguments, of which none is mandatory. The returned `AudioDataSource` object can </span>
<span class="sd">however greatly differ depending on the passed arguments. Further details can be found</span>
<span class="sd">in the respective method documentation. Note however the following two calls that will</span>
<span class="sd">create an `AudioDataSource` that read data from an audio file and from the built-in</span>
<span class="sd">microphone respectively.</span>

<span class="sd">    #!python</span>
<span class="sd">    from auditok import ADSFactory</span>
<span class="sd">    </span>
<span class="sd">    # Get an AudioDataSource from a file</span>
<span class="sd">    file_ads = ADSFactory.ads(filename = &quot;path/to/file/&quot;)</span>
<span class="sd">    </span>
<span class="sd">    # Get an AudioDataSource from the built-in microphone</span>
<span class="sd">    # The returned object has the default values for sampling</span>
<span class="sd">    # rate, sample width an number of channels. see method&#39;s</span>
<span class="sd">    # documentation for customized values </span>
<span class="sd">    mic_ads = ADSFactory.ads()</span>
<span class="sd">    </span>
<span class="sd">For `StreamTkenizer`, parameters `min_length`, `max_length` and `max_continuous_silence`</span>
<span class="sd">are expressed in term of number of frames. If you want a `max_length` of *2 seconds* for</span>
<span class="sd">your detected sound events and your *analysis window* is *10 ms* long, you have to specify</span>
<span class="sd">a `max_length` of 200 (`int(2. / (10. / 1000)) == 200`). For a `max_continuous_silence` of *300 ms*</span>
<span class="sd">for instance, the value to pass to StreamTokenizer is 30 (`int(0.3 / (10. / 1000)) == 30`).</span>


<span class="sd">Where do you get the size of the **analysis window** from?</span>


<span class="sd">Well this is a parameter you pass to `ADSFactory.ads`. By default `ADSFactory.ads` uses</span>
<span class="sd">an analysis window of 10 ms. the number of samples that 10 ms of signal contain will</span>
<span class="sd">vary depending on the sampling rate of your audio source (file, microphone, etc.).</span>
<span class="sd">For a sampling rate of 16KHz (16000 samples per second), we have 160 samples for 10 ms.</span>
<span class="sd">Therefore you can use block sizes of 160, 320, 1600 for analysis windows of 10, 20 and 100 </span>
<span class="sd">ms respectively.</span>

<span class="sd">    #!python</span>
<span class="sd">    from auditok import ADSFactory</span>
<span class="sd">    </span>
<span class="sd">    file_ads = ADSFactory.ads(filename = &quot;path/to/file/&quot;, block_size = 160)</span>
<span class="sd">    </span>
<span class="sd">    file_ads = ADSFactory.ads(filename = &quot;path/to/file/&quot;, block_size = 320)</span>
<span class="sd">    </span>
<span class="sd">    # If no sampling rate is specified, ADSFactory use 16KHz as the default</span>
<span class="sd">    # rate for the microphone. If you want to use a window of 100 ms, use </span>
<span class="sd">    # a block size of 1600 </span>
<span class="sd">    mic_ads = ADSFactory.ads(block_size = 1600)</span>
<span class="sd">    </span>
<span class="sd">So if your not sure what you analysis windows in seconds is, use the following:</span>

<span class="sd">    #!python</span>
<span class="sd">    my_ads = ADSFactory.ads(...)</span>
<span class="sd">    analysis_win_seconds = float(my_ads.get_block_size()) / my_ads.get_sampling_rate()</span>
<span class="sd">    analysis_window_ms = analysis_win_seconds * 1000</span>
<span class="sd">    </span>
<span class="sd">    # For a `max_continuous_silence` of 300 ms use:</span>
<span class="sd">    max_continuous_silence = int(300. / analysis_window_ms)</span>
<span class="sd">    </span>
<span class="sd">    # Which is the same as</span>
<span class="sd">    max_continuous_silence = int(0.3 / (analysis_window_ms / 1000))</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">Examples</span>
<span class="sd">--------</span>

<span class="sd">## Extract isolated phrases from an utterance</span>
<span class="sd">We will build an `AudioDataSource` using a wave file from  the database.</span>
<span class="sd">The file contains of isolated pronunciation of digits from 1 to 1</span>
<span class="sd">in Arabic as well as breath-in/out between 2 and 3. The code will play the</span>
<span class="sd"> original file then the detected sounds separately. Note that we use an </span>
<span class="sd">`energy_threshold` of 65, this parameter should be carefully chosen. It depends</span>
<span class="sd">on microphone quality, background noise and the amplitude of events you want to </span>
<span class="sd">detect.</span>

<span class="sd">    #!python</span>
<span class="sd">    from auditok import ADSFactory, AudioEnergyValidator, StreamTokenizer, player_for, dataset</span>
<span class="sd">     </span>
<span class="sd">    # We set the `record` argument to True so that we can rewind the source</span>
<span class="sd">    asource = ADSFactory.ads(filename=dataset.one_to_six_arabic_16000_mono_bc_noise, record=True)</span>
<span class="sd">     </span>
<span class="sd">    validator = AudioEnergyValidator(sample_width=asource.get_sample_width(), energy_threshold=65)</span>
<span class="sd">    </span>
<span class="sd">    # Defalut analysis window is 10 ms (float(asource.get_block_size()) / asource.get_sampling_rate())</span>
<span class="sd">    # min_length=20 : minimum length of a valid audio activity is 20 * 10 == 200 ms</span>
<span class="sd">    # max_length=4000 :  maximum length of a valid audio activity is 400 * 10 == 4000 ms == 4 seconds</span>
<span class="sd">    # max_continuous_silence=30 : maximum length of a tolerated  silence within a valid audio activity is 30 * 30 == 300 ms </span>
<span class="sd">    tokenizer = StreamTokenizer(validator=validator, min_length=20, max_length=400, max_continuous_silence=30)</span>
<span class="sd">    </span>
<span class="sd">    asource.open()</span>
<span class="sd">    tokens = tokenizer.tokenize(asource)</span>
<span class="sd">    </span>
<span class="sd">    # Play detected regions back</span>
<span class="sd">    </span>
<span class="sd">    player = player_for(asource)</span>
<span class="sd">    </span>
<span class="sd">    # Rewind and read the whole signal</span>
<span class="sd">    asource.rewind()</span>
<span class="sd">    original_signal = []</span>

<span class="sd">    while True:</span>
<span class="sd">       w = asource.read()</span>
<span class="sd">       if w is None:</span>
<span class="sd">          break</span>
<span class="sd">       original_signal.append(w)</span>
<span class="sd">       </span>
<span class="sd">    original_signal = &#39;&#39;.join(original_signal)</span>
<span class="sd">    </span>
<span class="sd">    print(&quot;Playing the original file...&quot;)</span>
<span class="sd">    player.play(original_signal)</span>
<span class="sd">    </span>
<span class="sd">    print(&quot;playing detected regions...&quot;)</span>
<span class="sd">    for t in tokens:</span>
<span class="sd">        print(&quot;Token starts at {0} and ends at {1}&quot;.format(t[1], t[2]))</span>
<span class="sd">        data = &#39;&#39;.join(t[0])</span>
<span class="sd">        player.play(data)</span>
<span class="sd">        </span>
<span class="sd">    assert len(tokens) == 8</span>
<span class="sd">    </span>

<span class="sd">The tokenizer extracts 8 audio regions from the signal, including all isolated digits</span>
<span class="sd">(from 1 to 6) as well as the 2-phase respiration of the subject. You might have noticed</span>
<span class="sd">that, in the original file, the last three digit are closer to each other than the </span>
<span class="sd">previous ones. If you wan them to be extracted as one single phrase, you can do so</span>
<span class="sd">by tolerating a larger continuous silence within a detection:</span>
<span class="sd"> </span>
<span class="sd">    #!python</span>
<span class="sd">    tokenizer.max_continuous_silence = 50</span>
<span class="sd">    asource.rewind()</span>
<span class="sd">    tokens = tokenizer.tokenize(asource)</span>
<span class="sd">    </span>
<span class="sd">    for t in tokens:</span>
<span class="sd">       print(&quot;Token starts at {0} and ends at {1}&quot;.format(t[1], t[2]))</span>
<span class="sd">       data = &#39;&#39;.join(t[0])</span>
<span class="sd">       player.play(data)</span>
<span class="sd">    </span>
<span class="sd">    assert len(tokens) == 6</span>
<span class="sd">        </span>
<span class="sd">         </span>
<span class="sd">## Trim leading and tailing silence</span>
<span class="sd"> </span>
<span class="sd">The  tokenizer in the following example is set up to remove the silence</span>
<span class="sd">that precedes the first acoustic activity or follows the last activity </span>
<span class="sd">in a record. It preserves whatever it founds between the two activities.</span>
<span class="sd">In other words, it removes the leading and tailing silence.</span>

<span class="sd">Sampling rate is 44100 sample per second, we&#39;ll use an analysis window of 100 ms</span>
<span class="sd">(i.e. bloc_ksize == 4410)</span>

<span class="sd">Energy threshold is 50.</span>

<span class="sd">The tokenizer will start accumulating windows up from the moment it encounters</span>
<span class="sd">the first analysis window of an energy &gt;= 50. ALL the following windows will be </span>
<span class="sd">kept regardless of their energy. At the end of the analysis, it will drop tailing</span>
<span class="sd"> windows with an energy below 50.</span>

<span class="sd">This is an interesting example because the audio file we&#39;re analyzing contains a very</span>
<span class="sd">brief noise that occurs within the leading silence. We certainly do want our tokenizer </span>
<span class="sd">to stop at this point and considers whatever it comes after as a useful signal.</span>
<span class="sd">To force the tokenizer to ignore that brief event we use two other parameters `init_min`</span>
<span class="sd">ans `init_max_silence`. By `init_min`=3 and `init_max_silence`=1 we tell the tokenizer</span>
<span class="sd">that a valid event must start with at least 3 noisy windows, between which there</span>
<span class="sd">is at most 1 silent window.</span>

<span class="sd">Still with this configuration we can get the tokenizer detect that noise as a valid event</span>
<span class="sd">(if it actually contains 3 consecutive noisy frames). To circummvent this we use an enough</span>
<span class="sd">large analysis window (here of 100 ms) to ensure that the brief noise be surrounded by a much</span>
<span class="sd">longer silence and hence the energy of the overall analysis window will be below 50.</span>

<span class="sd">When using a shorter analysis window (of 10ms for instance, block_size == 441), the brief</span>
<span class="sd">noise contributes more to energy calculation which yields an energy of over 50 for the window.</span>
<span class="sd">Again we can deal with this situation by using a higher energy threshold (55 for example)</span>
<span class="sd"> </span>
<span class="sd"> </span>
<span class="sd">    #!python</span>
<span class="sd">    from auditok import ADSFactory, AudioEnergyValidator, StreamTokenizer, player_for, dataset</span>

<span class="sd">    # record = True so that we&#39;ll be able to rewind the source.</span>
<span class="sd">    asource = ADSFactory.ads(filename=dataset.was_der_mensch_saet_mono_44100_lead_tail_silence,</span>
<span class="sd">             record=True, block_size=4410)</span>
<span class="sd">    asource.open()</span>

<span class="sd">    original_signal = []</span>
<span class="sd">    # Read the whole signal</span>
<span class="sd">    while True:</span>
<span class="sd">       w = asource.read()</span>
<span class="sd">       if w is None:</span>
<span class="sd">          break</span>
<span class="sd">       original_signal.append(w)</span>
<span class="sd">    </span>
<span class="sd">    original_signal = &#39;&#39;.join(original_signal)</span>
<span class="sd">    </span>
<span class="sd">    # rewind source</span>
<span class="sd">    asource.rewind()</span>
<span class="sd">    </span>
<span class="sd">    # Create a validator with an energy threshold of 50</span>
<span class="sd">    validator = AudioEnergyValidator(sample_width=asource.get_sample_width(), energy_threshold=50)</span>
<span class="sd">    </span>
<span class="sd">    # Create a tokenizer with an unlimited token length and continuous silence within a token</span>
<span class="sd">    # Note the DROP_TAILING_SILENCE mode that will ensure removing tailing silence</span>
<span class="sd">    trimmer = StreamTokenizer(validator, min_length = 20, max_length=99999999, init_min=3, init_max_silence=1,</span>
<span class="sd">                             max_continuous_silence=9999999, mode=StreamTokenizer.DROP_TAILING_SILENCE)</span>
<span class="sd">    </span>
<span class="sd">    </span>
<span class="sd">    tokens = trimmer.tokenize(asource)</span>
<span class="sd">    </span>
<span class="sd">    # Make sure we only have one token</span>
<span class="sd">    assert len(tokens) == 1, &quot;Should have detected one single token&quot;</span>
<span class="sd">    </span>
<span class="sd">    trimmed_signal = &#39;&#39;.join(tokens[0][0])</span>
<span class="sd">    </span>
<span class="sd">    player = player_for(asource)</span>
<span class="sd">    </span>
<span class="sd">    print(&quot;Playing original signal (with leading and tailing silence)...&quot;)</span>
<span class="sd">    player.play(original_signal)</span>
<span class="sd">    print(&quot;Playing trimmed signal...&quot;)</span>
<span class="sd">    player.play(trimmed_signal)</span>
<span class="sd">    </span>


<span class="sd">## Online audio signal processing</span>

<span class="sd">In the next example, audio data is directely acquired from the built-in microphone.</span>
<span class="sd">The `tokenize` method is passed a callback function so that audio activities</span>
<span class="sd">are delivered as soon as they are detected. Each detected activity is played</span>
<span class="sd">back using the build-in audio output device.</span>

<span class="sd">As mentionned before , Signal energy is strongly related to many factors such</span>
<span class="sd">microphone sensitivity, background noise (including noise inherent to the hardware), </span>
<span class="sd">distance and your operating system sound settings. Try a lower `energy_threshold`</span>
<span class="sd">if your noise does not seem to be detected and a higher threshold if you notice</span>
<span class="sd">an over detection (echo method prints a detection where you have made no noise).</span>

<span class="sd">    #!python</span>
<span class="sd">    from auditok import ADSFactory, AudioEnergyValidator, StreamTokenizer, player_for</span>
<span class="sd">     </span>
<span class="sd">    # record = True so that we&#39;ll be able to rewind the source.</span>
<span class="sd">    # max_time = 10: read 10 seconds from the microphone</span>
<span class="sd">    asource = ADSFactory.ads(record=True, max_time=10)</span>
<span class="sd">    </span>
<span class="sd">    validator = AudioEnergyValidator(sample_width=asource.get_sample_width(), energy_threshold=50)</span>
<span class="sd">    tokenizer = StreamTokenizer(validator=validator, min_length=20, max_length=250, max_continuous_silence=30)</span>
<span class="sd">    </span>
<span class="sd">    player = player_for(asource)</span>
<span class="sd">    </span>
<span class="sd">    def echo(data, start, end):</span>
<span class="sd">       print(&quot;Acoustic activity at: {0}--{1}&quot;.format(start, end))</span>
<span class="sd">       player.play(&#39;&#39;.join(data))</span>
<span class="sd">       </span>
<span class="sd">    asource.open()</span>
<span class="sd">    </span>
<span class="sd">    tokenizer.tokenize(asource, callback=echo)</span>

<span class="sd">If you want to re-run the tokenizer after changing of one or many parameters, use the following code:</span>

<span class="sd">    #!python</span>
<span class="sd">    asource.rewind()</span>
<span class="sd">    # change energy threshold for example</span>
<span class="sd">    tokenizer.validator.set_energy_threshold(55)</span>
<span class="sd">    tokenizer.tokenize(asource, callback=echo)</span>

<span class="sd">In case you want to play the whole recorded signal back use:</span>

<span class="sd">    #!python</span>
<span class="sd">    player.play(asource.get_audio_source().get_data_buffer())</span>
<span class="sd">    </span>

<span class="sd">Contributing</span>
<span class="sd">------------</span>
<span class="sd">`auditok` is on [GitHub](https://github.com/amsehili). You&#39;re welcome to fork</span>
<span class="sd">it and contribute.</span>


<span class="sd">@author: Amine SEHILI &lt;amine.sehili@gmail.com&gt;</span>
<span class="sd">September, 2015</span>

<span class="sd">License</span>
<span class="sd">-------</span>

<span class="sd">This package is published under GNU GPL Version 3.</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">core</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">io</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">util</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">dataset</span>

<span class="n">__version__</span> <span class="o">=</span> <span class="s">&quot;0.1.3&quot;</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">



    <h2 class="section-title" id="header-submodules">Sub-modules</h2>
      <div class="item">
      <p class="name"><a href="core.m.html">auditok.core</a></p>
      
  
    <div class="desc"><p>September 2015
@author: Amine SEHILI <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p></div>

      </div>
      <div class="item">
      <p class="name"><a href="dataset.m.html">auditok.dataset</a></p>
      
  
    <div class="desc"><p>This module contains links to audio files you can use for test purposes.</p>
<p>September 2015
@author: Amine SEHILI <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p></div>

      </div>
      <div class="item">
      <p class="name"><a href="io.m.html">auditok.io</a></p>
      
  
    <div class="desc"><p>Module for low-level audio input-output operations. </p>
<p>September 2015
@author: Amine SEHILI <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p></div>

      </div>
      <div class="item">
      <p class="name"><a href="util.m.html">auditok.util</a></p>
      
  
    <div class="desc"><p>September 2015
@author: Amine SEHILI <a href="&#109;&#97;&#105;&#108;&#116;&#111;&#58;&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;">&#97;&#109;&#105;&#110;&#101;&#46;&#115;&#101;&#104;&#105;&#108;&#105;&#64;&#103;&#109;&#97;&#105;&#108;&#46;&#99;&#111;&#109;</a></p></div>

      </div>
  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.1</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
